## üî• THE BRUTAL 4-HOUR DAILY PLAN

This is a no-nonsense, test-driven daily plan for completing the serverless migration in 20 days with only 4 focused hours per day. Every day has clear success criteria. If you fail a test, you don't move forward. Period.

### Week 1: Proof of Concept or Die Trying (Days 1-5)

#### Day 1 (4 hours): Infrastructure - Prove AWS Actually Works
**Objective**: Validate AWS infrastructure setup works end-to-end.

**Hour 1**: Create S3 bucket, DynamoDB users table, Lambda execution role
- Create S3 bucket `javumbo-user-dbs` with versioning enabled
- Create DynamoDB table `javumbo-users` (partition key: username)
- Create DynamoDB table `javumbo-user-locks` with TTL enabled
- Create IAM role `javumbo-lambda-role` with S3, DynamoDB, CloudWatch permissions

**Hour 2**: Deploy a HELLO WORLD Lambda that reads/writes to S3 and DynamoDB
- Create simple Lambda function that writes test data to S3 and DynamoDB
- Verify Lambda can access both services with proper permissions
- Test Lambda invocation via AWS CLI

**Hour 3**: Create API Gateway endpoint pointing to Lambda
- Create HTTP API Gateway `javumbo-api`
- Configure Lambda integration
- Create catch-all route `ANY /{proxy+}`

**Hour 4**: Run Tests 1.1-1.5 from Phase 1
- Test 1.1: S3 bucket upload/download/verify
- Test 1.2: DynamoDB put/get/delete operations
- Test 1.3: Lambda invocation
- Test 1.4: API Gateway integration
- Test 1.5: IAM permissions validation

**SUCCESS CRITERIA**:
- ‚úÖ Can hit API Gateway URL and get response from Lambda
- ‚úÖ Lambda can read/write to S3
- ‚úÖ Lambda can read/write to DynamoDB
- ‚úÖ All 5 tests pass
- ‚ùå If ANY test fails ‚Üí Fix before Day 2. Your AWS setup is TRASH.

---

#### Day 2 (4 hours): S3 SQLite Download/Upload - The Make or Break Day
**Objective**: Prove the core S3 SQLite pattern works with acceptable latency.

**Hour 1**: Code the `S3SQLiteConnection` context manager (basic version, no caching yet)
- Implement `__enter__`: Download .anki2 file from S3 to `/tmp`, open SQLite connection
- Implement `__exit__`: Commit changes, close connection, upload back to S3
- Handle `NoSuchKey` exception for new users (create empty database)

**Hour 2**: Write Test 2.1 (new user DB creation) and make it PASS
- Create test that instantiates `S3SQLiteConnection` for new user
- Verify new Anki database created with proper schema (col, cards, notes tables)
- Verify file uploaded to S3

**Hour 3**: Write Test 2.2 (read/write persistence) and make it PASS
- Insert data in first connection
- Read data in second connection
- Verify data persisted across connections

**Hour 4**: Measure actual latency
- Time 10 sequential requests: download ‚Üí open ‚Üí query ‚Üí close ‚Üí upload
- Calculate average, min, max latency
- Document baseline metrics

**SUCCESS CRITERIA**:
- ‚úÖ Can create new user database in S3
- ‚úÖ Data persists across connections
- ‚úÖ S3 download+upload completes (even if slow)
- ‚ö†Ô∏è If latency >500ms on average ‚Üí Note it, but acceptable for now (we optimize later)
- ‚ùå If downloads fail or data doesn't persist ‚Üí Your S3 approach is TRASH.

---

#### Day 3 (4 hours): Caching - Prove You Can Beat Latency
**Objective**: Implement Lambda container caching and measure performance improvement.

**Hour 1**: Add Lambda container caching to `S3SQLiteConnection` (Solution 1A)
- Add global `db_cache` dictionary
- Implement `_check_cache()`: Check if file exists in `/tmp` and cache entry is fresh
- Store ETag and timestamp in cache

**Hour 2**: Write Test 2.3 (cache speedup test) and make it PASS
- First access: measure cold request time
- Second access: measure warm request time (should use cache)
- Assert warm request is 2x+ faster

**Hour 3**: Run 50 sequential requests with the same user
- Measure cache hit rate
- Measure average latency for warm vs cold requests
- Document findings

**Hour 4**: Debug and optimize cache behavior
- If cache hit rate <70% ‚Üí Debug cache invalidation logic
- If warm requests not 2x+ faster ‚Üí Profile and fix bottlenecks
- Add cache TTL logic (5 minutes default)

**SUCCESS CRITERIA**:
- ‚úÖ Cache hit rate ‚â•70% for sequential requests
- ‚úÖ Warm requests are 2x+ faster than cold requests
- ‚úÖ Average warm request latency <100ms
- ‚ùå If cache doesn't work ‚Üí Your caching logic is TRASH.

---

#### Day 4 (4 hours): Conflict Detection - Prove Data Won't Get Lost
**Objective**: Implement S3 ETag optimistic locking to prevent concurrent write conflicts.

**Hour 1**: Implement S3 ETag optimistic locking in `S3SQLiteConnection` (Solution 2A)
- Store ETag from `get_object()` in `__enter__`
- Use `IfMatch` condition in `put_object()` in `__exit__`
- Handle `PreconditionFailed` exception ‚Üí raise `ConflictError`

**Hour 2**: Write Test 2.4 (conflict detection) and make it PASS
- Create two `S3SQLiteConnection` instances with cache disabled
- Both download same version (same ETag)
- Both modify data
- First to exit succeeds, second raises `ConflictError`

**Hour 3**: Simulate 10 concurrent writes from different "Lambda instances" (threads)
- Use `ThreadPoolExecutor` to simulate concurrent Lambda invocations
- Track how many succeed vs. conflict
- Verify NO DATA LOSS occurs

**Hour 4**: Analyze conflict rate and retry logic
- If conflicts result in data loss (silent overwrites) ‚Üí CRITICAL BUG, fix immediately
- Document expected conflict rate for typical usage patterns
- Design client-side retry strategy

**SUCCESS CRITERIA**:
- ‚úÖ Conflicts MUST raise `ConflictError`, never silently lose data
- ‚úÖ Test 2.4 passes (conflict detected)
- ‚úÖ Concurrent write simulation: 0% data loss
- ‚ùå If any silent data loss ‚Üí Your locking is TRASH. This is NON-NEGOTIABLE.

---

#### Day 5 (4 hours): DynamoDB Users - Prove Auth Works
**Objective**: Migrate user authentication from SQLite to DynamoDB.

**Hour 1**: Code `UserRepository` class for DynamoDB
- Implement `create_user()`: Hash password with bcrypt, store in DynamoDB
- Implement `get_user()`: Retrieve user by username
- Implement `verify_password()`: Compare hashed password
- Implement `update_user()`: Update user attributes

**Hour 2**: Write Test 2.5 (user CRUD) and make it PASS
- Create user
- Attempt duplicate user creation (should fail)
- Get user and verify data
- Verify correct password (should succeed)
- Verify wrong password (should fail)
- Update user and verify changes

**Hour 3**: Add `/tmp` cleanup utility and Test 2.6
- Implement `cleanup_tmp_directory()`: Remove files older than 10 minutes
- Check `/tmp` usage, remove oldest files if >80% full
- Write test that creates 5 cached files, ages 3 of them, runs cleanup, verifies 2 remain

**Hour 4**: Code review everything from Week 1
- Review all code written (S3SQLiteConnection, UserRepository, cleanup)
- Ensure error handling is robust
- Add logging for debugging
- Document any edge cases or limitations

**SUCCESS CRITERIA**:
- ‚úÖ All CRUD operations work in DynamoDB
- ‚úÖ Password hashing/verification works
- ‚úÖ `/tmp` cleanup removes old files
- ‚úÖ All Week 1 tests pass (Tests 1.1-1.5, 2.1-2.6)
- ‚ùå If any test fails ‚Üí Week 2 will be HELL. Fix it NOW.

---

### Week 2: Flask Integration - Make It Real (Days 6-10)

#### Day 6 (4 hours): Lambda Handler + Local Dev Mode
**Objective**: Wrap Flask app for Lambda while preserving local development.

**Hour 1**: Create `lambda_handler.py` with awsgi wrapper
- `pip install awsgi`
- Import Flask app
- Create `handler(event, context)` that calls `awsgi.response(app, event, context)`
- Call `cleanup_tmp_directory()` at start of each request

**Hour 2**: Modify `app.py` to detect Lambda vs local mode
- Set `IS_LAMBDA = os.environ.get('AWS_LAMBDA_FUNCTION_NAME') is not None`
- If Lambda: Use JWT for sessions, set environment variables
- If local: Use filesystem sessions, load from `.env`

**Hour 3**: Test local mode still works (Test 3.1)
- Run Flask app locally: `python app.py`
- Test `/register` and `/login` endpoints with curl
- Verify existing SQLite authentication works unchanged

**Hour 4**: Deploy Lambda and test with simple `/health` endpoint
- Add `/health` endpoint that returns `{"status": "healthy"}`
- Package Lambda deployment: create zip with dependencies
- Deploy to Lambda, test via API Gateway
- If 500 errors ‚Üí Debug Lambda logs in CloudWatch

**SUCCESS CRITERIA**:
- ‚úÖ Local development works unchanged
- ‚úÖ Lambda returns 200 for `/health` endpoint via API Gateway
- ‚ùå If local dev breaks ‚Üí You broke backward compatibility, ROLLBACK.
- ‚ùå If Lambda has 500 errors ‚Üí Your Flask adapter is TRASH.

---

#### Day 7 (4 hours): Authentication Refactor
**Objective**: Make authentication work in Lambda mode with JWT.

**Hour 1**: Install `flask-jwt-extended`, update `/login` endpoint
- `pip install flask-jwt-extended`
- Add `JWTManager` initialization in Lambda mode
- Update `/login` to call `UserRepository.verify_password()` in Lambda mode
- Return JWT token with `create_access_token(identity=username)`

**Hour 2**: Update `/register` endpoint to use DynamoDB + S3SQLiteConnection
- In Lambda mode: Call `UserRepository.create_user()`
- Create new S3 database: `with S3SQLiteConnection(username) as conn: pass`
- Return success/failure response

**Hour 3**: Write Test 3.2 (Lambda auth) and make it PASS
- Simulate Lambda event for `/register` with test user
- Verify user created in DynamoDB
- Simulate Lambda event for `/login`
- Verify JWT token returned

**Hour 4**: Test 3.3 (protected routes)
- Add `@jwt_required()` decorator to protected route (e.g., `/api/decks`)
- Test with valid JWT token (should succeed)
- Test without token (should return 401)

**SUCCESS CRITERIA**:
- ‚úÖ Can register user via Lambda (stored in DynamoDB + S3)
- ‚úÖ Can login and receive JWT token
- ‚úÖ Protected routes require valid JWT
- ‚ùå If auth doesn't work ‚Üí JWT config is TRASH.

---

#### Day 8 (4 hours): Core API Routes Migration (Part 1)
**Objective**: Migrate deck-related endpoints to use S3SQLiteConnection.

**Hour 1**: Update `/api/decks` GET endpoint
- Detect Lambda mode: get username from `get_jwt_identity()` vs `session['username']`
- Wrap database access: `with S3SQLiteConnection(username) as conn:`
- Keep existing SQLite query logic unchanged
- Return deck list

**Hour 2**: Update `/api/decks` POST endpoint (create deck)
- Same pattern: get username, wrap with `S3SQLiteConnection`
- Insert new deck into user's database
- Return new deck ID

**Hour 3**: Write Test 3.4 for deck operations
- Simulate Lambda events for GET /api/decks (should return empty list initially)
- Simulate Lambda event for POST /api/decks (create deck)
- Simulate Lambda event for GET /api/decks again (should show new deck)

**Hour 4**: Deploy to Lambda and test manually
- Package and deploy updated Lambda code
- Use Postman/curl to test deck operations via API Gateway
- Verify S3 database is updated after creating deck
- If operations fail ‚Üí Debug with CloudWatch logs

**SUCCESS CRITERIA**:
- ‚úÖ Can list decks via API Gateway
- ‚úÖ Can create deck (verified in S3)
- ‚úÖ Test 3.4 passes
- ‚ùå If deck operations fail ‚Üí S3SQLiteConnection integration is BROKEN.

---

#### Day 9 (4 hours): Core API Routes Migration (Part 2)
**Objective**: Migrate card and review endpoints.

**Hour 1-2**: Update `/api/cards` endpoints (GET, POST)
- GET: List cards for a deck
- POST: Add new card to deck
- Wrap with `S3SQLiteConnection(username) as conn:`
- Keep existing Anki schema queries unchanged

**Hour 3**: Update `/api/review` GET endpoint (start review session)
- Query cards due for review using SM-2 algorithm
- Return list of cards to review
- THIS IS CRITICAL: Review scheduling is core functionality

**Hour 4**: Test card and review operations
- Add cards to deck via Lambda
- Start review session
- Verify cards returned match expected due dates
- If review scheduling breaks ‚Üí SM-2 logic is CORRUPTED

**SUCCESS CRITERIA**:
- ‚úÖ Can add cards via API Gateway
- ‚úÖ Can start review session
- ‚úÖ Review logic works correctly
- ‚ùå If review logic breaks ‚Üí Your database migration BROKE the algorithm.

---

#### Day 10 (4 hours): Review Submission + Stats
**Objective**: Complete review flow and statistics endpoints.

**Hour 1**: Update `/api/review` POST endpoint (submit review)
- Receive card ID and rating (1-4)
- Update card's next review date using SM-2
- Update review history (revlog table)
- Handle concurrent modification with conflict detection

**Hour 2**: Update `/api/stats` endpoint
- Query review history from user's database
- Calculate statistics (cards reviewed, retention rate, etc.)
- Return statistics JSON

**Hour 3**: Write Test 3.5 (concurrent modifications)
- Simulate 2 concurrent review submissions for same user
- Verify one succeeds, one may get 409 conflict
- Verify NO DATA LOSS (critical)

**Hour 4**: Run conflict simulation
- Use ThreadPoolExecutor to simulate 10 concurrent reviews
- Measure conflict rate
- Verify all reviews either succeed or return 409 (never silently fail)
- If >10% data loss ‚Üí Go back to Day 4, locking is STILL TRASH

**SUCCESS CRITERIA**:
- ‚úÖ Can submit reviews and verify updates in S3
- ‚úÖ Statistics endpoint works
- ‚úÖ Concurrent reviews handled gracefully (0% data loss)
- ‚ùå If data loss occurs ‚Üí CRITICAL FAILURE. Do not proceed to Week 3.

---

### Week 3: Polish & Optimize (Days 11-15)

#### Day 11 (4 hours): Export + Binary Response Handling
**Objective**: Implement database export to .anki2 format.

**Hour 1**: Update `/api/export` to return .anki2 file from S3
- Download user's database from S3
- Return as binary file download
- Set proper Content-Type and Content-Disposition headers

**Hour 2**: Handle binary response encoding for API Gateway
- API Gateway requires base64 encoding for binary responses
- Set `isBase64Encoded: true` in Lambda response
- Test with curl download

**Hour 3**: Write Test 3.6 (export validation)
- Simulate export request
- Decode base64 response
- Verify it's a valid SQLite file (starts with "SQLite format 3")
- Check file size is reasonable

**Hour 4**: Download exported file and verify in Anki desktop
- Export from Lambda
- Save to local file
- Open in Anki desktop app
- Verify decks and cards display correctly
- If corrupted ‚Üí Binary encoding is TRASH

**SUCCESS CRITERIA**:
- ‚úÖ Export returns .anki2 file
- ‚úÖ File is valid SQLite database
- ‚úÖ Opens in Anki desktop without errors
- ‚ùå If corrupted ‚Üí Your binary encoding is BROKEN.

---

#### Day 12 (4 hours): Cold Start Optimization
**Objective**: Reduce cold start latency to acceptable levels.

**Hour 1**: Implement lazy module loading (Solution 4C)
- Move heavy imports (boto3, sqlite3) inside functions
- Import only when needed
- Measure import time reduction

**Hour 2**: Optimize deployment package (Solution 4D)
- Remove unnecessary files (tests, docs, *.pyc)
- Use slim dependencies where possible
- Reduce zip file size

**Hour 3**: Set up CloudWatch Events for scheduled warming (Solution 4B)
- Create CloudWatch Events rule: trigger every 5 minutes
- Lambda checks if warming event, returns immediately
- Keeps Lambda warm during business hours

**Hour 4**: Measure cold start vs warm start latency
- Wait 10 minutes for Lambda to go cold
- Measure first request (cold start)
- Measure subsequent requests (warm)
- Document findings: cold vs warm latency

**SUCCESS CRITERIA**:
- ‚úÖ Cold starts <2s (vs 3s+ before optimization)
- ‚úÖ Warm starts <200ms
- ‚úÖ Scheduled warming reduces cold starts by 80%+
- üìä Document actual metrics for future reference

---

#### Day 13 (4 hours): Frontend Integration
**Objective**: Update React frontend to work with Lambda backend.

**Hour 1**: Update React app to store JWT in localStorage
- After successful login: `localStorage.setItem('token', response.data.token)`
- Add logout: `localStorage.removeItem('token')`

**Hour 2**: Configure axios to send Authorization header
- Create axios interceptor
- Add `Authorization: Bearer ${token}` to all requests
- Handle 401 responses (redirect to login)

**Hour 3**: Update `.env.production` with API Gateway URL
- Set `VITE_API_BASE_URL` to API Gateway endpoint
- Build frontend: `npm run build`
- Test locally with production API

**Hour 4**: Deploy frontend to S3 + CloudFront
- Create S3 bucket for frontend
- Upload build files
- Create CloudFront distribution
- Test end-to-end: frontend ‚Üí API Gateway ‚Üí Lambda ‚Üí S3/DynamoDB
- If API calls fail ‚Üí CORS config is TRASH

**SUCCESS CRITERIA**:
- ‚úÖ Frontend can communicate with Lambda backend
- ‚úÖ JWT authentication works end-to-end
- ‚úÖ All features work (decks, cards, review, stats, export)
- ‚ùå If CORS errors ‚Üí Fix API Gateway CORS settings.

---

#### Day 14 (4 hours): Error Handling + Retry Logic
**Objective**: Make conflict handling transparent to users.

**Hour 1**: Add ConflictError handler to Flask app
- `@app.errorhandler(ConflictError)`
- Return JSON: `{'success': False, 'error': 'conflict', 'retry': True}`
- Set status code 409

**Hour 2**: Update frontend to retry on 409 conflicts
- Wrap API calls with retry logic
- Exponential backoff: 100ms, 200ms, 400ms
- Max 3 retries
- Show user-friendly message if all retries fail

**Hour 3**: Test concurrent operations from multiple browser tabs
- Open app in 2 tabs with same user
- Submit reviews simultaneously
- Verify one succeeds immediately, other retries automatically
- User should not see error message

**Hour 4**: Stress test retry logic
- Simulate 10 concurrent operations
- Verify all eventually succeed
- If conflicts cause UX issues ‚Üí Retry logic is TRASH

**SUCCESS CRITERIA**:
- ‚úÖ Users never see raw 409 errors
- ‚úÖ Conflicts handled gracefully with automatic retry
- ‚úÖ Multi-tab usage works without issues
- üìä Measure actual conflict rate in production-like scenario

---

#### Day 15 (4 hours): Monitoring + Logging
**Objective**: Set up observability for production debugging.

**Hour 1**: Add structured logging to Lambda (JSON format)
- Use `json.dumps()` for log messages
- Include: timestamp, request_id, username, operation, duration
- Log at appropriate levels: INFO, WARNING, ERROR

**Hour 2**: Create CloudWatch dashboard
- Lambda metrics: Invocations, Errors, Duration, ConcurrentExecutions
- S3 metrics: NumberOfObjects, BucketSizeBytes
- DynamoDB metrics: ConsumedReadCapacityUnits, ConsumedWriteCapacityUnits
- Save dashboard configuration

**Hour 3**: Set up alarms for error rate >5%
- Lambda errors alarm: threshold 5 errors in 5 minutes
- High latency alarm: average duration >3000ms
- Configure SNS topic for notifications (email/SMS)

**Hour 4**: Trigger errors intentionally and verify alarms fire
- Invoke Lambda with invalid payload 10 times
- Check if alarm triggers
- Verify notification received
- If no alerts ‚Üí Monitoring is USELESS

**SUCCESS CRITERIA**:
- ‚úÖ Can detect and diagnose issues in CloudWatch
- ‚úÖ Alarms trigger on error threshold
- ‚úÖ Logs are structured and searchable
- ‚úÖ Dashboard shows real-time metrics

---

### Week 4: Migration + Production (Days 16-20)

#### Day 16 (4 hours): Data Migration Script
**Objective**: Safely migrate production data to AWS.

**Hour 1**: Code `migrate_to_serverless.py` - admin.db to DynamoDB
- Read users from `admin.db` SQLite
- Use `batch_writer()` to bulk insert into DynamoDB
- Log each migrated user

**Hour 2**: Code user database migration to S3
- Iterate over `user_dbs/*.anki2` files
- Upload each to S3 with proper key structure
- Log each migrated database

**Hour 3**: Run migration on TEST data (not production yet!)
- Create test admin.db with 10 dummy users
- Create 10 test .anki2 files
- Run migration script
- Verify all data in AWS

**Hour 4**: Verify migration with Test 4.6
- Check user count matches (SQLite vs DynamoDB)
- Check database count matches (filesystem vs S3)
- Spot-check file integrity (compare file sizes)
- If ANY data missing ‚Üí Migration is BROKEN

**SUCCESS CRITERIA**:
- ‚úÖ Test migration succeeds with 100% data integrity
- ‚úÖ All users in DynamoDB
- ‚úÖ All databases in S3
- ‚úÖ File sizes match exactly
- ‚ùå If any data loss ‚Üí Do NOT migrate production. Fix script first.

---

#### Day 17 (4 hours): End-to-End Testing
**Objective**: Validate complete user workflows work in production environment.

**Hour 1**: Register new user in Lambda environment
- Use real API Gateway URL
- Register via frontend or curl
- Verify user in DynamoDB
- Verify database in S3

**Hour 2**: Create deck, add 10 cards, review 5 cards
- Complete full workflow via API Gateway
- Verify each step updates S3 database correctly
- Check review intervals are calculated correctly

**Hour 3**: Export deck and verify in Anki desktop
- Download .anki2 file
- Open in Anki desktop
- Verify all cards present
- Verify review history preserved

**Hour 4**: Have someone else test the app (wife, friend, colleague)
- Give them API URL
- Watch them use it (don't help)
- Note any confusion or errors
- If confused ‚Üí UX is TRASH, simplify

**SUCCESS CRITERIA**:
- ‚úÖ Full user workflow works without errors
- ‚úÖ External tester can use app successfully
- ‚úÖ Export opens in Anki desktop correctly
- üìä Document any UX issues for future fixes

---

#### Day 18 (4 hours): Performance Testing + Cost Estimation
**Objective**: Validate system handles load and costs are as predicted.

**Hour 1**: Use Apache Bench to simulate 100 concurrent users
- Install Apache Bench: `brew install httpd`
- Run load test: `ab -n 100 -c 10`
- Target endpoints: login, decks, cards, review

**Hour 2**: Monitor CloudWatch for errors, latency spikes, throttling
- Watch CloudWatch dashboard during load test
- Look for errors, throttling, high latency
- Check Lambda concurrent execution count

**Hour 3**: Calculate actual AWS costs from CloudWatch metrics
- Check Lambda invocation count
- Check S3 GET/PUT requests
- Check DynamoDB read/write capacity
- Estimate monthly cost based on 1 day of usage

**Hour 4**: Analyze and optimize if needed
- If costs >$5/month for 100 users ‚Üí Architecture is EXPENSIVE
- If latency spikes ‚Üí Add provisioned concurrency
- If throttling ‚Üí Increase Lambda concurrency limit
- Document actual vs predicted costs

**SUCCESS CRITERIA**:
- ‚úÖ System handles 100 concurrent users without errors
- ‚úÖ No Lambda throttling
- ‚úÖ Costs match predictions (~$1/month for 100 users)
- ‚úÖ 95th percentile latency <500ms
- ‚ö†Ô∏è If costs 5x higher ‚Üí Review S3 PUT operations, may need caching improvements

---

#### Day 19 (4 hours): Production Migration
**Objective**: Cutover production to serverless architecture.

**Hour 1**: Backup EVERYTHING
- `cp admin.db admin.db.backup_$(date +%Y%m%d)`
- `tar -czf user_dbs_backup_$(date +%Y%m%d).tar.gz user_dbs/`
- Upload backups to S3 backup bucket
- Verify backups are complete

**Hour 2**: Run production migration script
- Double-check you're migrating correct data
- Run `migrate_to_serverless.py`
- Monitor progress (should show each user/database migrated)
- Verify counts match

**Hour 3**: Cutover - Update DNS/CloudFront to point to Lambda
- Update frontend environment variable to Lambda API URL
- Rebuild and deploy frontend
- Test with production domain
- Keep old infrastructure running (don't delete yet)

**Hour 4**: Monitor for 1 hour
- Watch error rate in CloudWatch
- Monitor user complaints (support channels)
- Check latency, throughput
- If error rate >1% ‚Üí ROLLBACK IMMEDIATELY

**ROLLBACK PLAN**:
- Revert frontend to old API URL
- Rebuild and redeploy frontend
- Old infrastructure still running, can restore instantly

**SUCCESS CRITERIA**:
- ‚úÖ Production running on serverless with <1% error rate
- ‚úÖ Users can login and use app
- ‚úÖ No data loss
- ‚ùå If >1% errors or user complaints ‚Üí ROLLBACK, debug, try again tomorrow

---

#### Day 20 (4 hours): Documentation + Postmortem
**Objective**: Document the migration for future reference.

**Hour 1**: Document final architecture decisions
- Update docs with actual AWS resource names (ARNs, URLs)
- Document any deviations from original plan
- Note any challenges overcome

**Hour 2**: Update deployment docs for serverless
- Write step-by-step deploy instructions
- Document environment variables required
- Add troubleshooting section

**Hour 3**: Write postmortem
- What worked well?
- What was TRASH and had to be fixed?
- What would you do differently?
- Lessons learned
- Cost analysis: predicted vs actual

**Hour 4**: Celebrate or cry, depending on Days 1-19
- If successful: Enjoy your ~95% cost savings
- If failed: Analyze what went wrong, plan recovery
- Update this document with real-world findings
- Share knowledge with team

**SUCCESS CRITERIA**:
- ‚úÖ Future you can understand and maintain this system
- ‚úÖ New developer can deploy from docs
- ‚úÖ Lessons learned documented
- üéâ System running, users happy, costs low

---

## The BRUTAL Truth

This plan assumes:
- ‚úÖ You know Python, Flask, AWS basics (Lambda, S3, DynamoDB, API Gateway)
- ‚úÖ You can debug when things break (they WILL break)
- ‚úÖ You actually execute 4 focused hours per day (no social media, no meetings, no distractions)
- ‚úÖ You have AWS account with billing enabled
- ‚úÖ You have existing Javumbo application running locally for testing

**Critical Rules**:
1. **NO SKIPPING TESTS**: If a test fails, you don't move to next day. Period.
2. **NO SHORTCUTS**: Every test must pass before proceeding. Cutting corners = data loss.
3. **BACKUP EVERYTHING**: Before production migration, backup twice. Verify backups.
4. **MONITOR OBSESSIVELY**: During cutover (Day 19), watch CloudWatch like a hawk.
5. **ROLLBACK READY**: Have rollback plan and be prepared to execute in <5 minutes.

**Failure Points** (where most migrations die):
- **Day 2**: S3 download/upload too slow ‚Üí Need caching (Day 3 fixes this)
- **Day 4**: Conflict detection doesn't work ‚Üí DATA LOSS (unacceptable, must fix)
- **Day 10**: Concurrent writes lose data ‚Üí Locking is broken (go back to Day 4)
- **Day 19**: Production cutover has >1% errors ‚Üí ROLLBACK, debug, retry

**Success Metrics** (by Day 20):
- ‚úÖ 100% data integrity (zero data loss)
- ‚úÖ <1% error rate in production
- ‚úÖ <300ms average latency (warm requests)
- ‚úÖ <$1/month costs for 100 users
- ‚úÖ All users can use app without noticing the migration

**Now prove this plan works. Start with Day 1 and report back.**

If Test 1.1 fails, we fix it before moving forward. No shortcuts, no excuses.
